{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a7d244-1d23-4455-90ea-78d8550ecfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (8.3.99)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sucheti\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cb621-ca39-4319-9003-90042289f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99  Python-3.12.7 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=55\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    762037  ultralytics.nn.modules.head.Detect           [55, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,021,573 parameters, 3,021,557 gradients, 8.3 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\labels\\train images.cache... 0 images, 15210 b\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\labels\\train images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\labels\\valid images.cache... 0 images, 1431 back\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\labels\\valid images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/951 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model (Nano version for speed)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train the model\n",
    "model.train(data= r\"C:\\Users\\SUCHETI\\OneDrive\\Desktop\\DatasetObjectDetection\\data.yaml\", epochs=50, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6f84a3-a87a-4c1d-b23a-0556c1afb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698754de-0544-48ab-ab6c-339de52ae6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 2 ties, 301.4ms\n",
      "Speed: 8.4ms preprocess, 301.4ms inference, 25.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 169.3ms\n",
      "Speed: 3.2ms preprocess, 169.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 164.0ms\n",
      "Speed: 3.1ms preprocess, 164.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 142.7ms\n",
      "Speed: 2.6ms preprocess, 142.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 163.3ms\n",
      "Speed: 3.2ms preprocess, 163.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 160.7ms\n",
      "Speed: 2.4ms preprocess, 160.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 161.0ms\n",
      "Speed: 2.4ms preprocess, 161.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 162.9ms\n",
      "Speed: 3.0ms preprocess, 162.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.3ms\n",
      "Speed: 2.4ms preprocess, 157.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 157.9ms\n",
      "Speed: 3.2ms preprocess, 157.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 198.8ms\n",
      "Speed: 66.2ms preprocess, 198.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 167.4ms\n",
      "Speed: 6.4ms preprocess, 167.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 179.7ms\n",
      "Speed: 2.5ms preprocess, 179.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 298.2ms\n",
      "Speed: 5.5ms preprocess, 298.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 275.9ms\n",
      "Speed: 3.5ms preprocess, 275.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 256.0ms\n",
      "Speed: 4.7ms preprocess, 256.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 273.7ms\n",
      "Speed: 3.0ms preprocess, 273.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 280.2ms\n",
      "Speed: 2.9ms preprocess, 280.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 177.1ms\n",
      "Speed: 3.6ms preprocess, 177.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 247.8ms\n",
      "Speed: 6.1ms preprocess, 247.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 200.3ms\n",
      "Speed: 8.2ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 234.4ms\n",
      "Speed: 2.7ms preprocess, 234.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 270.7ms\n",
      "Speed: 4.4ms preprocess, 270.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 180.2ms\n",
      "Speed: 7.6ms preprocess, 180.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 283.4ms\n",
      "Speed: 2.8ms preprocess, 283.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 287.8ms\n",
      "Speed: 3.3ms preprocess, 287.8ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 302.6ms\n",
      "Speed: 4.7ms preprocess, 302.6ms inference, 68.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 360.8ms\n",
      "Speed: 6.9ms preprocess, 360.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 214.5ms\n",
      "Speed: 2.7ms preprocess, 214.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 307.6ms\n",
      "Speed: 17.7ms preprocess, 307.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 1 cell phone, 145.6ms\n",
      "Speed: 2.3ms preprocess, 145.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 174.3ms\n",
      "Speed: 2.8ms preprocess, 174.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 143.2ms\n",
      "Speed: 3.3ms preprocess, 143.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 102.4ms\n",
      "Speed: 2.4ms preprocess, 102.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 98.4ms\n",
      "Speed: 1.6ms preprocess, 98.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 97.1ms\n",
      "Speed: 1.8ms preprocess, 97.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 83.3ms\n",
      "Speed: 1.8ms preprocess, 83.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 86.5ms\n",
      "Speed: 2.1ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 117.3ms\n",
      "Speed: 2.7ms preprocess, 117.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 93.7ms\n",
      "Speed: 3.2ms preprocess, 93.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.8ms\n",
      "Speed: 2.5ms preprocess, 93.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 146.7ms\n",
      "Speed: 3.4ms preprocess, 146.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 88.2ms\n",
      "Speed: 1.6ms preprocess, 88.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 88.7ms\n",
      "Speed: 1.5ms preprocess, 88.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 122.0ms\n",
      "Speed: 3.2ms preprocess, 122.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 85.3ms\n",
      "Speed: 2.2ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 189.8ms\n",
      "Speed: 2.8ms preprocess, 189.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 207.2ms\n",
      "Speed: 3.1ms preprocess, 207.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 174.8ms\n",
      "Speed: 3.2ms preprocess, 174.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 139.7ms\n",
      "Speed: 3.4ms preprocess, 139.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 109.2ms\n",
      "Speed: 3.8ms preprocess, 109.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 89.5ms\n",
      "Speed: 2.7ms preprocess, 89.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 115.9ms\n",
      "Speed: 3.7ms preprocess, 115.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 133.6ms\n",
      "Speed: 3.4ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 100.7ms\n",
      "Speed: 3.3ms preprocess, 100.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 102.2ms\n",
      "Speed: 2.9ms preprocess, 102.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 87.5ms\n",
      "Speed: 2.7ms preprocess, 87.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 2 cell phones, 87.2ms\n",
      "Speed: 3.3ms preprocess, 87.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 88.2ms\n",
      "Speed: 2.5ms preprocess, 88.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 91.7ms\n",
      "Speed: 3.5ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 90.7ms\n",
      "Speed: 2.9ms preprocess, 90.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 1 cell phone, 95.7ms\n",
      "Speed: 2.9ms preprocess, 95.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 1 cell phone, 90.9ms\n",
      "Speed: 1.9ms preprocess, 90.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 1 cell phone, 86.7ms\n",
      "Speed: 2.7ms preprocess, 86.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 1 cell phone, 88.3ms\n",
      "Speed: 1.7ms preprocess, 88.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 1 cell phone, 83.7ms\n",
      "Speed: 2.9ms preprocess, 83.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 1 cell phone, 84.5ms\n",
      "Speed: 1.9ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 81.9ms\n",
      "Speed: 2.2ms preprocess, 81.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 88.2ms\n",
      "Speed: 2.3ms preprocess, 88.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 remote, 1 cell phone, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 80.3ms\n",
      "Speed: 3.5ms preprocess, 80.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 84.2ms\n",
      "Speed: 2.0ms preprocess, 84.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 89.5ms\n",
      "Speed: 1.5ms preprocess, 89.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 1 cell phone, 111.7ms\n",
      "Speed: 2.4ms preprocess, 111.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 1 cell phone, 99.2ms\n",
      "Speed: 2.0ms preprocess, 99.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 1 cell phone, 120.9ms\n",
      "Speed: 1.6ms preprocess, 120.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 tie, 1 cell phone, 224.3ms\n",
      "Speed: 2.8ms preprocess, 224.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 ties, 1 cell phone, 214.1ms\n",
      "Speed: 3.5ms preprocess, 214.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 ties, 1 cell phone, 205.4ms\n",
      "Speed: 3.5ms preprocess, 205.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 ties, 1 cell phone, 194.1ms\n",
      "Speed: 3.0ms preprocess, 194.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 3 ties, 163.9ms\n",
      "Speed: 2.6ms preprocess, 163.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 167.6ms\n",
      "Speed: 3.8ms preprocess, 167.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 155.2ms\n",
      "Speed: 2.9ms preprocess, 155.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 165.3ms\n",
      "Speed: 3.2ms preprocess, 165.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 4 ties, 153.5ms\n",
      "Speed: 3.3ms preprocess, 153.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 141.6ms\n",
      "Speed: 2.5ms preprocess, 141.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 134.8ms\n",
      "Speed: 1.8ms preprocess, 134.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 122.6ms\n",
      "Speed: 2.5ms preprocess, 122.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 103.4ms\n",
      "Speed: 2.8ms preprocess, 103.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 94.4ms\n",
      "Speed: 2.2ms preprocess, 94.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 1 cell phone, 100.2ms\n",
      "Speed: 1.9ms preprocess, 100.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 100.5ms\n",
      "Speed: 1.8ms preprocess, 100.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 94.6ms\n",
      "Speed: 1.9ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 101.9ms\n",
      "Speed: 2.7ms preprocess, 101.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 97.0ms\n",
      "Speed: 2.2ms preprocess, 97.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 100.4ms\n",
      "Speed: 2.6ms preprocess, 100.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 93.0ms\n",
      "Speed: 2.7ms preprocess, 93.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 98.5ms\n",
      "Speed: 2.2ms preprocess, 98.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 102.2ms\n",
      "Speed: 2.7ms preprocess, 102.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 98.1ms\n",
      "Speed: 2.8ms preprocess, 98.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 97.0ms\n",
      "Speed: 2.5ms preprocess, 97.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 1 cell phone, 157.8ms\n",
      "Speed: 9.6ms preprocess, 157.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 134.8ms\n",
      "Speed: 2.9ms preprocess, 134.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 123.6ms\n",
      "Speed: 2.5ms preprocess, 123.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 122.6ms\n",
      "Speed: 2.7ms preprocess, 122.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 123.2ms\n",
      "Speed: 2.2ms preprocess, 123.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 108.0ms\n",
      "Speed: 1.9ms preprocess, 108.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 108.5ms\n",
      "Speed: 2.2ms preprocess, 108.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 107.2ms\n",
      "Speed: 1.9ms preprocess, 107.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 98.7ms\n",
      "Speed: 1.8ms preprocess, 98.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 111.0ms\n",
      "Speed: 2.4ms preprocess, 111.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 100.4ms\n",
      "Speed: 2.1ms preprocess, 100.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 111.8ms\n",
      "Speed: 2.3ms preprocess, 111.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 110.3ms\n",
      "Speed: 2.5ms preprocess, 110.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 103.0ms\n",
      "Speed: 2.2ms preprocess, 103.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 ties, 101.0ms\n",
      "Speed: 2.7ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 ties, 117.0ms\n",
      "Speed: 1.7ms preprocess, 117.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 121.7ms\n",
      "Speed: 2.2ms preprocess, 121.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 123.0ms\n",
      "Speed: 2.5ms preprocess, 123.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 118.4ms\n",
      "Speed: 2.7ms preprocess, 118.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 4 ties, 121.4ms\n",
      "Speed: 2.4ms preprocess, 121.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 ties, 119.2ms\n",
      "Speed: 2.9ms preprocess, 119.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 ties, 126.2ms\n",
      "Speed: 2.3ms preprocess, 126.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 126.0ms\n",
      "Speed: 6.6ms preprocess, 126.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 3 ties, 123.5ms\n",
      "Speed: 2.5ms preprocess, 123.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tie, 146.6ms\n",
      "Speed: 2.8ms preprocess, 146.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 166.2ms\n",
      "Speed: 3.0ms preprocess, 166.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 ties, 169.6ms\n",
      "Speed: 2.5ms preprocess, 169.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 tie, 158.5ms\n",
      "Speed: 2.8ms preprocess, 158.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 153.6ms\n",
      "Speed: 2.7ms preprocess, 153.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.1ms\n",
      "Speed: 2.9ms preprocess, 155.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.2ms\n",
      "Speed: 3.0ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.8ms\n",
      "Speed: 3.2ms preprocess, 155.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 157.6ms\n",
      "Speed: 3.5ms preprocess, 157.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 1 backpack, 2 chairs, 3 laptops, 1 clock, 167.0ms\n",
      "Speed: 2.3ms preprocess, 167.0ms inference, 66.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 1 chair, 3 laptops, 165.4ms\n",
      "Speed: 3.4ms preprocess, 165.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 2 chairs, 1 laptop, 113.6ms\n",
      "Speed: 3.1ms preprocess, 113.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 99.0ms\n",
      "Speed: 2.9ms preprocess, 99.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 101.8ms\n",
      "Speed: 2.3ms preprocess, 101.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 2 laptops, 93.2ms\n",
      "Speed: 2.6ms preprocess, 93.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 snowboard, 1 chair, 2 laptops, 110.6ms\n",
      "Speed: 2.1ms preprocess, 110.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 1 chair, 1 laptop, 130.5ms\n",
      "Speed: 2.0ms preprocess, 130.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 1 chair, 3 laptops, 156.5ms\n",
      "Speed: 3.1ms preprocess, 156.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 1 suitcase, 1 chair, 2 laptops, 142.3ms\n",
      "Speed: 8.4ms preprocess, 142.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 suitcase, 1 chair, 2 laptops, 153.4ms\n",
      "Speed: 2.6ms preprocess, 153.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 suitcase, 2 laptops, 144.5ms\n",
      "Speed: 3.1ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2  # Import OpenCV\n",
    "from ultralytics import YOLO  # Import YOLOv8\n",
    "\n",
    "# Load the trained YOLOv8 model (ensure the correct path to your trained model)\n",
    "model = YOLO(r\"C:\\Users\\SUCHETI\\yolov8n.pt\")  \n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Open the webcam (0 = default camera)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)  # Run YOLO detection\n",
    "    frame = results[0].plot()  # Draw bounding boxes\n",
    "\n",
    "    cv2.imshow(\"Custom YOLOv8 Detection\", frame)  # Display the results\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b3bb621-79ce-4129-bd3d-a7eae88a603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "cap.release()  # Release the camera\n",
    "cv2.destroyAllWindows()  # Close any OpenCV windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c736162-c777-4c5d-b777-01ca3b8011ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
